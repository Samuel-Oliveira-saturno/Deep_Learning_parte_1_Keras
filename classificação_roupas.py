# -*- coding: utf-8 -*-
"""classificação_roupas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hXdTTUtXuHhY76GkwY6uOGR84xpRtlNQ

# Importando o Tensorflow e bibliotecas
"""

import tensorflow
from tensorflow import keras 
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import load_model

"""# importando o Dataset fashion_mnist"""

dataset = keras.datasets.fashion_mnist
((imagens_treino, identificacoes_treino),(imagens_teste, identificacoes_teste)) = dataset.load_data()

len(imagens_treino)

"""# exploração os dados

"""

len(imagens_treino)
imagens_treino.shape
imagens_teste.shape
len(identificacoes_teste)
identificacoes_treino.min()
identificacoes_treino.max()

"""# Exibir os dados"""

total_de_classificacoes = 10
nomes_de_classificacoes =['Camiseta', 'Calça', 'pullover',
                          'Vestido', 'Casaco', 'Sandália', 'Camisa', 
                          'Tênis', 'Bolsa', 'Bota']
'''
plt.imshow(imagens_treino[0])
plt.title(identificacoes_treino[0])

for imagem in range (10):
  plt.subplot(2, 5, imagem + 1)
  plt.imshow(imagens_treino[imagem])
  plt.title(nomes_de_classificacoes[identificacoes_treino[imagem]])
'''

plt.imshow(imagens_treino[0], cmap='gray')
plt.colorbar()

"""## Normalizando as imagens"""

imagens_treino = imagens_treino/255.0 #  ou flot(255)

"""## Criando, compilando, treinando e normalizando o modelo """

modelo = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(256, activation=tensorflow.nn.relu),
    keras.layers.Dropout(0.2),
    #keras.layers.Dense(128, activation=tensorflow.nn.relu),
    #keras.layers.Dense(64, activation=tensorflow.nn.relu),
    keras.layers.Dense(10, activation=tensorflow.nn.softmax)
])

modelo.compile(optimizer='adam', 
               loss='sparse_categorical_crossentropy',
               metrics=['accuracy'])

historico = modelo.fit(imagens_treino, identificacoes_treino, epochs=5, validation_split=0.2)

"""## Salvando e carregando o modelo treinado"""

modelo.save('modelo.h5')
modelo_salvo = load_model('modelo.h5')

historico

historico.history

historico.history['accuracy']

"""## Visualizando as acurácias de treino e validação por época """

plt.plot(historico.history['accuracy'])
plt.plot(historico.history['val_accuracy'])
plt.title('Acurácia por épocas')
plt.xlabel('epochs')
plt.ylabel('Accuracy')
plt.legend(['treino', 'validação'])

"""## Visualizando as perdas do treino por época """

plt.plot(historico.history['loss'])
plt.plot(historico.history['val_loss'])
plt.title('Perdas por épocas')
plt.xlabel('epochs')
plt.ylabel('Loss')
plt.legend(['treino', 'validação'])

"""## Testando o modelo salvo 

"""

testes = modelo.predict(imagens_teste)
print('resultado teste:', np.argmax(testes[1]))
print('número da imagem de teste:', identificacoes_teste[1])

"""# Avaliação do nosso modelo"""

perda_teste, acuracia_teste = modelo.evaluate(imagens_teste, identificacoes_teste)
print('Perda do teste:', perda_teste)
print('Acurária do teste:', acuracia_teste)

testes_modelo_salvo = modelo_salvo.predict(imagens_teste)
print('resultado teste modelo salvo:',np.argmax(testes_modelo_salvo [1]) )
print('número da imagem de teste:', identificacoes_teste[1])